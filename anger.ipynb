{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ahmadkhan242/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams  \n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd. read_csv(\"./anger/anger-ratings-0to1.train.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
    "val = pd. read_csv(\"./anger/anger-ratings-0to1.dev.target.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
    "val_gold = pd. read_csv(\"./anger/anger-ratings-0to1.dev.gold.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
    "test = pd. read_csv(\"./anger/anger-ratings-0to1.test.target.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])\n",
    "test_gold = pd. read_csv(\"./anger/anger-ratings-0to1.test.gold.txt\", sep=\"\\t\", names=['id', 'tweet', 'emotion', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_pred, y, print_metrics=True):\n",
    "    p1 = pearsonr(y_pred, y)[0]\n",
    "    s1 = spearmanr(y_pred, y)[0]\n",
    "    if print_metrics:\n",
    "        print(\"Validation Pearsonr: {}\".format(p1))\n",
    "        print(\"Validation Spearmanr: {}\".format(s1))\n",
    "#         print(\"Validation Pearsonr >= 0.5: {}\".format(p2))\n",
    "#         print(\"Validation Spearmanr >= 0.5: {}\".format(s2))\n",
    "    return np.array((p1, s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_train, X_test, y_train, y_test, val_X, val_y):\n",
    "    prediction_accuracy = {}\n",
    "    \n",
    "    # Random Forest Classifier\n",
    "    _RandomForestClassifier = RandomForestRegressor(n_estimators = 1000, oob_score=True)\n",
    "    _RandomForestClassifier.fit(X_train, y_train)\n",
    "    _RandomForestClassifier_prediction = _RandomForestClassifier.predict(X_test)\n",
    "#     prediction_accuracy['Random Forest'] = round(accuracy_score(_RandomForestClassifier_prediction, y_test)*100, 2)\n",
    "    val_RandomForestClassifier_prediction = _RandomForestClassifier.predict(val_X)\n",
    "#     prediction_accuracy['Val_Random Forest'] = round(accuracy_score(val_RandomForestClassifier_prediction, val_y)*100, 2)\n",
    "    \n",
    "    print(\"Random Forest \")\n",
    "    metrics(_RandomForestClassifier_prediction, y_test)\n",
    "    metrics(val_RandomForestClassifier_prediction, y_test)\n",
    "    \n",
    "#     # Support Vector Machine\n",
    "#     _SVC = SVC(C = 0.4, kernel = 'linear', gamma='auto')\n",
    "#     _SVC.fit(X_train, y_train)\n",
    "#     _SVC_prediction = _SVC.predict(X_test)\n",
    "#     prediction_accuracy['Support Vector Machine'] = round(accuracy_score(_SVC_prediction, y_test)*100, 2)\n",
    "#     val_SVC_prediction = _SVC.predict(val_X)\n",
    "#     prediction_accuracy['Val_Support Vector Machine'] = round(accuracy_score(val_SVC_prediction, val_y)*100, 2)\n",
    "    \n",
    "#     print(\"Support Vector Machine\")\n",
    "#     metrics(_SVC_prediction, y_test)\n",
    "#     metrics(val_SVC_prediction, y_test)\n",
    "    \n",
    "    #accuracy DataFram\n",
    "    prediction_accuracy_df = pd.DataFrame(prediction_accuracy.items(), columns=['Classifier', 'Accuracy'], index=None)\n",
    "    return prediction_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_stopwatch_approach(X, y, val_X, val_y):\n",
    "    # Label encoding the classes\n",
    "#     encoder = LabelEncoder()\n",
    "#     y = encoder.fit_transform(y)\n",
    "#     val_y = encoder.fit_transform(val_y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "    # Creating the vectorizer\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=1000, min_df=20, stop_words= STOPWORDS )\n",
    "    X_train = tfidf.fit_transform(X_train).toarray()\n",
    "    X_test = tfidf.transform(X_test).toarray()\n",
    "    val_X = tfidf.transform(val_X).toarray()\n",
    "    return X_train, X_test, y_train, y_test, val_X, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "Validation Pearsonr: 0.33644069914730007\n",
      "Validation Spearmanr: 0.276617336798586\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0e0a8fa54d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_stopwatch_approach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_gold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_gold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-0f05441f23b2>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(X_train, X_test, y_train, y_test, val_X, val_y)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RandomForestClassifier_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_RandomForestClassifier_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ebb00871e651>\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(y_pred, y, print_metrics)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(\"Validation Pearsonr >= 0.5: {}\".format(p2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         print(\"Validation Spearmanr >= 0.5: {}\".format(s2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p2' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test,val_X, val_y = simple_stopwatch_approach(train.tweet ,train.score , test_gold.tweet , test_gold.score )\n",
    "p_df = prediction(X_train, X_test, y_train, y_test, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
